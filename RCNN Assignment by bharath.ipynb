{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "efa19882",
   "metadata": {},
   "source": [
    "# RCNN Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8b41933",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "1. **Selective Search in R-CSSP:**\n",
    "   - Selective Search is an algorithm used for generating region proposals in object detection.\n",
    "   - R-CSSP seems to be a variation or combination of R-CNN (Region-based Convolutional Neural Network) and Selective Search.\n",
    "\n",
    "2. **Phases Involved in R-CSS:**\n",
    "   - Revision Proposal.\n",
    "   - Warp and Resize.\n",
    "   - Pre-trained CNN Architecture.\n",
    "   - Pre-trained SVM Model.\n",
    "   - Clean up.\n",
    "   - Implementation of Counting Log.\n",
    "\n",
    "3. **Possible Pre-trained CNNs in Pre-trained CSS Architecture:**\n",
    "   - Pre-trained CNN architectures like ResNet or VGG are commonly used.\n",
    "\n",
    "4. **How is SVM Implemented in R-CSS Framework:**\n",
    "   - SVM (Support Vector Machine) is likely used for classification, possibly after features are extracted from CNN.\n",
    "\n",
    "5. **Non-maximum Suppression in R-CSS:**\n",
    "   - It's a technique used to suppress multiple bounding box proposals for the same object, keeping only the most confident one.\n",
    "\n",
    "6. **Difference Between Fast R-CSS and R-CSSP:**\n",
    "   - Fast R-CSS is likely an optimized or improved version of R-CSS.\n",
    "   - Mathematical intuition may involve efficiency or accuracy improvements.\n",
    "\n",
    "7. **ROI Projection and ROI Pooling:**\n",
    "   - Regions of Interest (ROI) Projection involves mapping proposals onto the feature map.\n",
    "   - ROI Pooling is a method to extract fixed-size features from variable-sized ROIs.\n",
    "\n",
    "8. **Changes in Object Classifier Activation Function in Fast R-CSS:**\n",
    "   - The activation function of the object classifier may have been modified for better performance or efficiency.\n",
    "\n",
    "9. **Major Changes in Faster R-CSS Compared to Fast R-CSSP:**\n",
    "   - Faster R-CNN typically introduces improvements such as Region Proposal Network (RPN) for more efficient proposal generation.\n",
    "\n",
    "10. **Anchor Boxes Concept:**\n",
    "    - Anchor boxes are predefined bounding boxes of different scales and ratios used in object detection algorithms.\n",
    "\n",
    "11. **Implementing Faster R-CSS with a C^2C^ Dataset:**\n",
    "    - Dataset Preparation: Download, preprocess, and split into training and validation sets.\n",
    "    - Model Architecture: Use a pre-trained CNN like ResNet, customize RPN and RCNN.\n",
    "    - Training: Train the model on the training set with suitable loss functions.\n",
    "    - Validation: Evaluate the model on the validation set, calculate metrics like mAP.\n",
    "    - Inference: Implement an inference pipeline to detect objects in new images.\n",
    "    - Optional Enhancements: Implement techniques like Non-maximum Suppression (NMS) for better results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c94f39ab",
   "metadata": {},
   "source": [
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision.models.detection import FasterRCNN\n",
    "from torchvision.models.detection.rpn import AnchorGenerator\n",
    "from torchvision.transforms import functional as F\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "from torchvision.datasets import CocoDetection\n",
    "\n",
    "# Define the dataset and transform\n",
    "dataset = CocoDetection(root='path_to_dataset', annFile='path_to_annotations', transform=None)\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# Define data loaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=2, shuffle=True, num_workers=4, collate_fn=torch.utils.data._utils.collate.default_collate)\n",
    "val_loader = DataLoader(val_dataset, batch_size=2, shuffle=False, num_workers=4, collate_fn=torch.utils.data._utils.collate.default_collate)\n",
    "\n",
    "# Define the model\n",
    "backbone = torchvision.models.resnet50(pretrained=True)\n",
    "backbone.out_channels = 256  # Adjust based on the backbone architecture\n",
    "anchor_generator = AnchorGenerator(sizes=((32, 64, 128, 256, 512),), aspect_ratios=((0.5, 1.0, 2.0),))\n",
    "roi_pooler = torchvision.ops.MultiScaleRoIAlign(featmap_names=['0'], output_size=7, sampling_ratio=2)\n",
    "\n",
    "model = FasterRCNN(backbone, num_classes=len(dataset), rpn_anchor_generator=anchor_generator, box_roi_pool=roi_pooler)\n",
    "\n",
    "# Define the optimizer and loss function\n",
    "params = [p for p in model.parameters() if p.requires_grad]\n",
    "optimizer = torch.optim.SGD(params, lr=0.005, momentum=0.9, weight_decay=0.0005)\n",
    "lr_scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=3, gamma=0.1)\n",
    "\n",
    "# Training loop\n",
    "num_epochs = 10\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for images, targets in train_loader:\n",
    "        images = list(image for image in images)\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "        \n",
    "        loss_dict = model(images, targets)\n",
    "        losses = sum(loss for loss in loss_dict.values())\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        losses.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Validation loop\n",
    "    model.eval()\n",
    "    for images, targets in val_loader:\n",
    "        images = list(image for image in images)\n",
    "        targets = [{k: v for k, v in t.items()} for t in targets]\n",
    "\n",
    "        with torch.no_grad():\n",
    "            loss_dict = model(images, targets)\n",
    "\n",
    "    # Adjust learning rate\n",
    "    lr_scheduler.step()\n",
    "\n",
    "# Save or use the trained model for inference\n",
    "torch.save(model.state_dict(), 'faster_rcnn_model.pth')\n",
    "```\n",
    "\n",
    "This is a basic example, and you may need to customize it based on your specific dataset and requirements. Ensure that you have the necessary dependencies installed, and replace 'path_to_dataset' and 'path_to_annotations' with the actual paths to your dataset and annotations file. Additionally, you may need to adapt the data loading, transformation, and collation based on your dataset format."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a388719c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
