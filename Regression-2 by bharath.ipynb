{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "714dae5f",
   "metadata": {},
   "source": [
    "# Regression-2\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6ebfca8",
   "metadata": {},
   "source": [
    "# QUESTIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4cb5aaa",
   "metadata": {},
   "source": [
    "Q1. Explain the concept of R-squared in linear regression models. How is it calculated, and what does it \n",
    "represent?\n",
    "\n",
    "Q2. Define adjusted R-squared and explain how it differs from the regular R-squared. \n",
    "\n",
    "Q3. When is it more appropriate to use adjusted R-squared?\n",
    "\n",
    "Q4. What are RMSE, MSE, and MAE in the context of regression analysis? How are these metrics \n",
    "calculated, and what do they represent?\n",
    "\n",
    "Q5. Discuss the advantages and disadvantages of using RMSE, MSE, and MAE as evaluation metrics in \n",
    "regression analysis.\n",
    "\n",
    "Q6. Explain the concept of Lasso regularization. How does it differ from Ridge regularization, and when is \n",
    "it more appropriate to use?\n",
    "\n",
    "Q7. How do regularized linear models help to prevent overfitting in machine learning? Provide an \n",
    "example to illustrate.\n",
    "\n",
    "Q8. Discuss the limitations of regularized linear models and explain why they may not always be the best \n",
    "choice for regression analysis.\n",
    "\n",
    "Q9. You are comparing the performance of two regression models using different evaluation metrics. \n",
    "Model A has an RMSE of 10, while Model B has an MAE of 8. Which model would you choose as the better \n",
    "performer, and why? Are there any limitations to your choice of metric?\n",
    "\n",
    "Q10. You are comparing the performance of two regularized linear models using different types of \n",
    "regularization. Model A uses Ridge regularization with a regularization parameter of 0.1, while Model B \n",
    "uses Lasso regularization with a regularization parameter of 0.5. Which model would you choose as the \n",
    "better performer, and why? Are there any trade-offs or limitations to your choice of regularization \n",
    "method"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "435f4210",
   "metadata": {},
   "source": [
    "# SOLUTIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d969ef5a",
   "metadata": {},
   "source": [
    "\n",
    "Q1. **R-squared in Linear Regression:**\n",
    "   R-squared (Coefficient of Determination) is a statistical measure that represents the proportion of the variance in the dependent variable (response) that is explained by the independent variables (predictors) in a linear regression model. It's calculated as the ratio of the explained variance to the total variance of the dependent variable. R-squared values range from 0 to 1, where 1 indicates that all variability in the dependent variable is explained by the model, and 0 indicates no explanatory power.\n",
    "\n",
    "Q2. **Adjusted R-squared:**\n",
    "   Adjusted R-squared is an extension of R-squared that takes into account the number of predictors in the model and adjusts for the potential increase in R-squared due to adding more variables. It penalizes adding irrelevant variables that do not contribute much to the model's performance. Adjusted R-squared is calculated using the formula: \n",
    "   \n",
    "   Adjusted R-squared = 1 - [(1 - R-squared) * (n - 1) / (n - p - 1)]\n",
    "\n",
    "   Where 'n' is the number of observations and 'p' is the number of predictors.\n",
    "\n",
    "Q3. **When to Use Adjusted R-squared:**\n",
    "   Adjusted R-squared is more appropriate when comparing models with different numbers of predictors. It helps prevent overfitting by considering model complexity. Higher adjusted R-squared values indicate that the model has a good balance between explanatory power and model complexity.\n",
    "\n",
    "Q4. **RMSE, MSE, and MAE:**\n",
    "   - RMSE (Root Mean Squared Error): It's the square root of the average of the squared differences between predicted and actual values. RMSE gives a sense of the typical error magnitude.\n",
    "   - MSE (Mean Squared Error): It's the average of the squared differences between predicted and actual values. It emphasizes larger errors more than smaller ones.\n",
    "   - MAE (Mean Absolute Error): It's the average of the absolute differences between predicted and actual values. MAE gives a linear representation of error magnitude.\n",
    "\n",
    "Q5. **Advantages and Disadvantages of Evaluation Metrics:**\n",
    "   - RMSE: Penalizes larger errors more, sensitive to outliers.\n",
    "   - MSE: Similar to RMSE but lacks interpretability due to the square root.\n",
    "   - MAE: Easily interpretable, less sensitive to outliers.\n",
    "   These metrics help quantify the accuracy of predictions but can be influenced by outliers and scale differences.\n",
    "\n",
    "Q6. **Lasso Regularization:**\n",
    "   Lasso (Least Absolute Shrinkage and Selection Operator) is a regularization technique in linear regression that adds a penalty term to the cost function, forcing some coefficients to become exactly zero. This encourages feature selection and helps prevent overfitting by reducing model complexity. Lasso can be particularly useful when dealing with high-dimensional data.\n",
    "\n",
    "Q7. **Regularization and Overfitting:**\n",
    "   Regularized linear models (like Lasso and Ridge) help prevent overfitting by adding a penalty for large coefficient values. For example, in Lasso, some coefficients are driven to zero, effectively removing less relevant features and simplifying the model, which can improve generalization to new data.\n",
    "\n",
    "Q8. **Limitations of Regularized Linear Models:**\n",
    "   - May discard potentially useful features.\n",
    "   - Choice of regularization parameter can be challenging.\n",
    "   - Nonlinear relationships might not be well-captured.\n",
    "   - Interpretability of the coefficients can be compromised.\n",
    "\n",
    "Q9. **Comparing Models with Different Metrics:**\n",
    "   In this scenario, both RMSE and MAE indicate different aspects of model performance. RMSE emphasizes larger errors, while MAE provides an average absolute error. To choose the better model, it depends on your priorities. If you want to focus more on reducing large errors, go with RMSE (Model A). If you want a balanced view of overall errors, go with MAE (Model B).\n",
    "\n",
    "Q10. **Comparing Regularized Models:**\n",
    "   Model A (Ridge) uses a lower regularization parameter (0.1) compared to Model B (Lasso, 0.5). Lower values indicate less aggressive regularization. Generally, Lasso is more aggressive at shrinking coefficients to zero, making Model B more likely to discard features. The choice depends on the balance between feature selection (Lasso) and less intense regularization (Ridge) needed for your problem. You should consider the importance of interpretability and the desired trade-off between model complexity and simplicity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b9726b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
