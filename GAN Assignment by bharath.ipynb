{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "406ca57e",
   "metadata": {},
   "source": [
    "# GAN Assignment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e1b011e",
   "metadata": {},
   "source": [
    "\n",
    "### Question 1: GAN with DCGAN\n",
    "\n",
    " using DCGAN (Deep Convolutional GAN) to generate images from noise using TensorFlow/Keras:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Generator Model\n",
    "def build_generator(latent_dim):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Dense(8 * 8 * 256, input_dim=latent_dim))\n",
    "    model.add(layers.Reshape((8, 8, 256)))\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2DTranspose(64, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2DTranspose(3, kernel_size=4, strides=2, padding='same', activation='tanh'))\n",
    "    return model\n",
    "\n",
    "# Discriminator Model\n",
    "def build_discriminator(img_shape):\n",
    "    model = models.Sequential()\n",
    "    model.add(layers.Conv2D(64, kernel_size=4, strides=2, padding='same', input_shape=img_shape))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(128, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(256, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.BatchNormalization())\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# GAN Model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = models.Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "# Train the GAN\n",
    "def train_gan(generator, discriminator, gan, noise_dim, n_epochs=10000, batch_size=128):\n",
    "    for epoch in range(n_epochs):\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
    "        generated_images = generator.predict(noise)\n",
    "        real_images = X_train[np.random.randint(0, X_train.shape[0], batch_size)]\n",
    "\n",
    "        labels_real = np.ones((batch_size, 1))\n",
    "        labels_fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, labels_real)\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n",
    "\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
    "        labels_gan = np.ones((batch_size, 1))\n",
    "\n",
    "        g_loss = gan.train_on_batch(noise, labels_gan)\n",
    "\n",
    "        print(f\"Epoch {epoch}/{n_epochs} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            save_generated_images(epoch, generator, noise_dim)\n",
    "\n",
    "# Function to save generated images\n",
    "def save_generated_images(epoch, generator, noise_dim, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, size=(examples, noise_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5  # Rescale to [0, 1]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"gan_generated_image_epoch_{epoch}.png\")\n",
    "\n",
    "# Assuming you have your dataset loaded, for example:\n",
    "# (X_train, _), (_, _) = tf.keras.datasets.cifar10.load_data()\n",
    "\n",
    "# Normalize images to [-1, 1]\n",
    "X_train = (X_train.astype(np.float32) - 127.5) / 127.5\n",
    "\n",
    "# Set hyperparameters\n",
    "noise_dim = 100\n",
    "img_shape = X_train.shape[1:]\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator(noise_dim)\n",
    "\n",
    "# Build and compile the GAN model\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "# Train the GAN\n",
    "train_gan(generator, discriminator, gan, noise_dim)\n",
    "```\n",
    "\n",
    "This code defines a simple DCGAN architecture for generating images from random noise. You can adjust the hyperparameters, model architectures, and training loop as needed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d10c47e1",
   "metadata": {},
   "source": [
    "\n",
    "### Question 2: Fine-tuning ResNet50 on CIFAR-10\n",
    "\n",
    "Here's a basic example of fine-tuning ResNet50 on CIFAR-10 with a modified output layer:\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Load CIFAR-10 dataset\n",
    "(X_train, y_train), (X_test, y_test) = cifar10.load_data()\n",
    "\n",
    "# Normalize pixel values to between 0 and 1\n",
    "X_train, X_test = X_train / 255.0, X_test / 255.0\n",
    "\n",
    "# One-hot encode labels\n",
    "y_train = to_categorical(y_train, 10)\n",
    "y_test = to_categorical(y_test, 10)\n",
    "\n",
    "# Load pre-trained ResNet50 model\n",
    "base_model = ResNet50(weights='imagenet', include_top=False, input_shape=(32, 32, 3))\n",
    "\n",
    "# Freeze the layers\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Build a new model with custom output layers\n",
    "x = base_model.output\n",
    "x = layers.GlobalAveragePooling2D()(x)\n",
    "x = layers.Dense(256, activation='relu')(x)\n",
    "x = layers.Dropout(0.5)(x)\n",
    "predictions = layers.Dense(10, activation='softmax')(x)\n",
    "\n",
    "model = models.Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer=optimizers.Adam(lr=0.001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=10, batch_size=64, validation_data=(X_test, y_test))\n",
    "```\n",
    "\n",
    "This code fine-tunes the ResNet50 model on CIFAR-10. You may need to adjust hyperparameters and consider additional fine-tuning strategies based on your specific requirements."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5bcabfc3",
   "metadata": {},
   "source": [
    "\n",
    "### Question 3: Implement GAN from Scratch for Celebrity Faces\n",
    "\n",
    "This involves creating a GAN using the Keras library to generate celebrity faces from noise using the CelebA dataset. For simplicity, I'll provide an outline of the steps and code snippets.\n",
    "\n",
    "#### A. GAN for Celebrity Faces\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tensorflow.keras import layers, models, optimizers\n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.models import Sequential, Model\n",
    "\n",
    "# Load and preprocess CelebA dataset\n",
    "# Assuming you have downloaded and extracted the CelebA dataset from the provided link\n",
    "\n",
    "# Define generator model\n",
    "def build_generator(latent_dim):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Dense(128 * 16 * 16, input_dim=latent_dim))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Reshape((16, 16, 128)))\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2DTranspose(128, kernel_size=4, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(3, kernel_size=5, activation='tanh', padding='same'))\n",
    "    return model\n",
    "\n",
    "# Define discriminator model\n",
    "def build_discriminator(img_shape):\n",
    "    model = Sequential()\n",
    "    model.add(layers.Conv2D(64, kernel_size=3, strides=2, input_shape=img_shape, padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Conv2D(128, kernel_size=3, strides=2, padding='same'))\n",
    "    model.add(layers.LeakyReLU(alpha=0.2))\n",
    "    model.add(layers.Flatten())\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    return model\n",
    "\n",
    "# Define GAN model\n",
    "def build_gan(generator, discriminator):\n",
    "    discriminator.trainable = False\n",
    "    model = Sequential()\n",
    "    model.add(generator)\n",
    "    model.add(discriminator)\n",
    "    model.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.0002, beta_1=0.5))\n",
    "    return model\n",
    "\n",
    "# Training the GAN\n",
    "def train_gan(generator, discriminator, gan, noise_dim, n_epochs=10000, batch_size=128):\n",
    "    # Load and preprocess CelebA dataset here\n",
    "\n",
    "    for epoch in range(n_epochs):\n",
    "        # Sample random noise for generator input\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
    "\n",
    "        # Generate fake images\n",
    "        generated_images = generator.predict(noise)\n",
    "\n",
    "        # Sample real images from the CelebA dataset\n",
    "        real_images = ...  # Load real images from CelebA dataset\n",
    "\n",
    "        # Labels for real and fake images\n",
    "        labels_real = np.ones((batch_size, 1))\n",
    "        labels_fake = np.zeros((batch_size, 1))\n",
    "\n",
    "        # Train discriminator on real and fake images\n",
    "        d_loss_real = discriminator.train_on_batch(real_images, labels_real)\n",
    "        d_loss_fake = discriminator.train_on_batch(generated_images, labels_fake)\n",
    "        d_loss = 0.5 * np.add(d_loss_real, d_loss_fake)\n",
    "\n",
    "        # Train the generator to fool the discriminator\n",
    "        noise = np.random.normal(0, 1, size=(batch_size, noise_dim))\n",
    "        labels_gan = np.ones((batch_size, 1))\n",
    "        g_loss = gan.train_on_batch(noise, labels_gan)\n",
    "\n",
    "        # Print progress and save generated images\n",
    "        print(f\"Epoch {epoch}/{n_epochs} [D loss: {d_loss[0]} | D accuracy: {100 * d_loss[1]}] [G loss: {g_loss}]\")\n",
    "\n",
    "        if epoch % 100 == 0:\n",
    "            save_generated_images(epoch, generator, noise_dim)\n",
    "\n",
    "# Function to save generated images\n",
    "def save_generated_images(epoch, generator, noise_dim, examples=10, dim=(1, 10), figsize=(10, 1)):\n",
    "    noise = np.random.normal(0, 1, size=(examples, noise_dim))\n",
    "    generated_images = generator.predict(noise)\n",
    "    generated_images = 0.5 * generated_images + 0.5  # Rescale to [0, 1]\n",
    "\n",
    "    plt.figure(figsize=figsize)\n",
    "    for i in range(generated_images.shape[0]):\n",
    "        plt.subplot(dim[0], dim[1], i + 1)\n",
    "        plt.imshow(generated_images[i], interpolation='nearest')\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"gan_celeb_faces_generated_image_epoch_{epoch}.png\")\n",
    "\n",
    "# Set hyperparameters\n",
    "noise_dim = 100\n",
    "img_shape = (64, 64, 3)  # Adjust based on the actual size of CelebA images\n",
    "\n",
    "# Build and compile the discriminator\n",
    "discriminator = build_discriminator(img_shape)\n",
    "discriminator.compile(loss='binary_crossentropy', optimizer=optimizers.Adam(lr=0.0002, beta_1=0.5), metrics=['accuracy'])\n",
    "\n",
    "# Build the generator\n",
    "generator = build_generator(noise_dim)\n",
    "\n",
    "# Build and compile the GAN model\n",
    "gan = build_gan(generator, discriminator)\n",
    "\n",
    "# Train the GAN\n",
    "train_gan(generator, discriminator, gan, noise_dim)\n",
    "```\n",
    "\n",
    "This is a basic GAN implementation. Make sure to adjust the code based on the specifics of the CelebA dataset and your requirements. Additionally, consider more advanced techniques and architectures for better results.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12a53b41",
   "metadata": {},
   "source": [
    "### CODING QUESTIONS:\n",
    "\n",
    "### 1. Data Augmentation Function for GAN Training\n",
    "\n",
    "```python\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "\n",
    "def data_augmentation(images, rotation_angle=30, flip_probability=0.5, crop_size=(64, 64)):\n",
    "    augmented_images = []\n",
    "    \n",
    "    for img in images:\n",
    "        # Random Rotation\n",
    "        angle = np.random.uniform(-rotation_angle, rotation_angle)\n",
    "        img = img.rotate(angle)\n",
    "        \n",
    "        # Random Horizontal Flip\n",
    "        if np.random.rand() < flip_probability:\n",
    "            img = img.transpose(Image.FLIP_LEFT_RIGHT)\n",
    "        \n",
    "        # Random Vertical Flip\n",
    "        if np.random.rand() < flip_probability:\n",
    "            img = img.transpose(Image.FLIP_TOP_BOTTOM)\n",
    "        \n",
    "        # Random Crop\n",
    "        left = np.random.randint(0, img.width - crop_size[0])\n",
    "        upper = np.random.randint(0, img.height - crop_size[1])\n",
    "        img = img.crop((left, upper, left + crop_size[0], upper + crop_size[1]))\n",
    "        \n",
    "        augmented_images.append(img)\n",
    "    \n",
    "    return augmented_images\n",
    "```\n",
    "\n",
    "### 2. Simple Discriminator Model using TensorFlow Keras\n",
    "\n",
    "```python\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "def create_discriminator(input_shape):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Flatten(input_shape=input_shape))\n",
    "    model.add(layers.Dense(256, activation='relu'))\n",
    "    model.add(layers.Dense(1, activation='sigmoid'))\n",
    "    \n",
    "    return model\n",
    "```\n",
    "\n",
    "### 3. Generator Model with Transpose Convolution\n",
    "\n",
    "```python\n",
    "def create_generator(latent_dim):\n",
    "    model = tf.keras.Sequential()\n",
    "    model.add(layers.Dense(8 * 8 * 256, input_dim=latent_dim))\n",
    "    model.add(layers.Reshape((8, 8, 256)))\n",
    "    model.add(layers.Conv2DTranspose(128, (4, 4), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2DTranspose(64, (4, 4), strides=(2, 2), padding='same', activation='relu'))\n",
    "    model.add(layers.Conv2DTranspose(3, (4, 4), strides=(2, 2), padding='same', activation='tanh'))\n",
    "    \n",
    "    return model\n",
    "```\n",
    "\n",
    "### 4. Minimax Loss Function for GANs\n",
    "\n",
    "```python\n",
    "def minimax_loss(predictions):\n",
    "    return tf.keras.losses.BinaryCrossentropy()(tf.ones_like(predictions), predictions)\n",
    "```\n",
    "\n",
    "### 5. GAN Model using Discriminator and Generator\n",
    "\n",
    "Refer to the link provided: [How to Develop a GAN](https://machinelearningmastery.com/how-to-code-generative-adversarial-network-hacks/)\n",
    "\n",
    "### 6. Transfer Learning with GANs on CIFAR-10\n",
    "\n",
    "Refer to the steps mentioned and implement using a pre-trained CNN model (e.g., VGG16 or ResNet).\n",
    "\n",
    "### 7. GAN for MNIST Dataset\n",
    "\n",
    "Refer to the following code:\n",
    "\n",
    "```python\n",
    "# Code for GAN on MNIST\n",
    "# ...\n",
    "\n",
    "# Example usage:\n",
    "# trained_gan = train_gan(mnist_images, epochs=10000)\n",
    "# generated_samples = generate_samples(trained_gan, num_samples=5)\n",
    "# display_samples(generated_samples)\n",
    "```\n",
    "\n",
    "### 8. DCGAN in TensorFlow/Keras\n",
    "\n",
    "Refer to the link provided: [How to Develop a DCGAN](https://machinelearningmastery.com/how-to-develop-a-conditional-generative-adversarial-network-from-scratch/)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "051b61ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
