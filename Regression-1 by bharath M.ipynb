{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "893513c1",
   "metadata": {},
   "source": [
    "# Regression-1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "151bae84",
   "metadata": {},
   "source": [
    "# QUESTIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9bca8ab",
   "metadata": {},
   "source": [
    "Q1. Explain the difference between simple linear regression and multiple linear regression. Provide an \n",
    "example of each.\n",
    "\n",
    "Q2. Discuss the assumptions of linear regression. How can you check whether these assumptions hold in \n",
    "a given dataset?\n",
    "\n",
    "Q3. How do you interpret the slope and intercept in a linear regression model? Provide an example using \n",
    "a real-world scenario.\n",
    "\n",
    "Q4. Explain the concept of gradient descent. How is it used in machine learning?\n",
    "\n",
    "Q5. Describe the multiple linear regression model. How does it differ from simple linear regression?\n",
    "\n",
    "Q6. Explain the concept of multicollinearity in multiple linear regression. How can you detect and \n",
    "address this issue?\n",
    "\n",
    "Q7. Describe the polynomial regression model. How is it different from linear regression?\n",
    "\n",
    "Q8. What are the advantages and disadvantages of polynomial regression compared to linear \n",
    "regression? In what situations would you prefer to use polynomial regression?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d280ad59",
   "metadata": {},
   "source": [
    "# SOLUTIONS:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00991fcb",
   "metadata": {},
   "source": [
    "\n",
    "Q1. **Simple Linear Regression vs. Multiple Linear Regression:**\n",
    "   - **Simple Linear Regression:** In simple linear regression, there is one dependent variable (response) and one independent variable (predictor). It models the relationship between the two variables using a straight line.\n",
    "   - **Multiple Linear Regression:** In multiple linear regression, there is one dependent variable and two or more independent variables. It models the relationship between the dependent variable and multiple predictors using a linear equation.\n",
    "\n",
    "   Example of Simple Linear Regression:\n",
    "   Imagine you want to predict a student's exam score (dependent variable) based on the number of hours they studied (independent variable). This is a simple linear regression problem because you're using only one predictor (hours studied).\n",
    "\n",
    "   Example of Multiple Linear Regression:\n",
    "   Now, consider predicting a person's salary (dependent variable) based on their years of experience and education level (two independent variables). This would require multiple linear regression since you have two predictors.\n",
    "\n",
    "Q2. **Assumptions of Linear Regression and Checking Them:**\n",
    "   The assumptions of linear regression include linearity, independence of errors, homoscedasticity (constant variance of errors), normality of errors, and absence of multicollinearity. These assumptions can be checked using techniques like residual plots, normality tests (e.g., Shapiro-Wilk), scatterplots, and variance inflation factor (VIF) for multicollinearity.\n",
    "\n",
    "Q3. **Interpretation of Slope and Intercept:**\n",
    "   In a linear regression model (y = mx + b), the slope (m) represents the change in the dependent variable (y) for a unit change in the independent variable (x), while the intercept (b) represents the value of the dependent variable when the independent variable is zero.\n",
    "   \n",
    "   Example: Let's say you have a linear regression model predicting house prices based on the square footage of the house. The slope indicates how much the price changes for each additional square foot, and the intercept represents the estimated price when the house has zero square footage (which is not meaningful in this context).\n",
    "\n",
    "Q4. **Gradient Descent:**\n",
    "   Gradient descent is an optimization technique used in machine learning to find the minimum of a function. In the context of linear regression, it's used to iteratively adjust the model's parameters (coefficients) to minimize the difference between the predicted values and the actual values (the cost function). It calculates the gradient (slope) of the cost function and updates the parameters in the opposite direction of the gradient to reach the optimal solution.\n",
    "\n",
    "Q5. **Multiple Linear Regression:**\n",
    "   Multiple linear regression is an extension of simple linear regression to include multiple independent variables. The model equation becomes: y = b0 + b1*x1 + b2*x2 + ... + bn*xn, where y is the dependent variable, b0 is the intercept, b1 to bn are the coefficients for the independent variables x1 to xn.\n",
    "\n",
    "Q6. **Multicollinearity in Multiple Linear Regression:**\n",
    "   Multicollinearity occurs when two or more independent variables in a multiple regression model are highly correlated, making it difficult to isolate their individual effects. It can lead to unstable coefficient estimates and difficulty in interpreting the model. Multicollinearity can be detected using correlation matrices or VIF values. To address multicollinearity, you can consider removing one of the correlated variables or using dimensionality reduction techniques like principal component analysis (PCA).\n",
    "\n",
    "Q7. **Polynomial Regression:**\n",
    "   Polynomial regression is a type of regression where the relationship between the dependent variable and the independent variable(s) is modeled as an nth-degree polynomial equation. It allows for curved fits to the data, unlike linear regression.\n",
    "\n",
    "Q8. **Advantages and Disadvantages of Polynomial Regression:**\n",
    "   Advantages:\n",
    "   - Can capture more complex relationships in the data.\n",
    "   - Can provide a better fit when the relationship isn't linear.\n",
    "\n",
    "   Disadvantages:\n",
    "   - Prone to overfitting if the degree of the polynomial is too high.\n",
    "   - Can lead to unstable predictions outside the range of the training data.\n",
    "   \n",
    "   Situations to use polynomial regression:\n",
    "   Polynomial regression can be useful when the relationship between variables is nonlinear and cannot be well-modeled using linear regression. However, caution should be exercised to prevent overfitting. It's typically employed when there's a theoretical or empirical reason to believe a polynomial relationship exists in the data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24acff70",
   "metadata": {},
   "source": [
    "# -------------------------------------END--------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
