{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1043657c",
   "metadata": {},
   "source": [
    "# IMAGE SCRAPPER ASSIGNMENT"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebd697b8",
   "metadata": {},
   "source": [
    "**Q1. Write a python program to extract the video URL of the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "07302ea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video URLs of the first five videos have been saved in video_urls.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extract the video URLs of the first five videos\n",
    "video_urls = []\n",
    "for link in soup.select(\".yt-simple-endpoint.style-scope.ytd-grid-video-renderer\"):\n",
    "    video_urls.append(\"https://www.youtube.com\" + link[\"href\"])\n",
    "\n",
    "# Prepare data for CSV\n",
    "data = [{\"Video URL\": video_url} for video_url in video_urls[:5]]\n",
    "\n",
    "# Save the data in a CSV file\n",
    "filename = \"video_urls.csv\"\n",
    "fieldnames = [\"Video URL\"]\n",
    "with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"Video URLs of the first five videos have been saved in\", filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0476736c",
   "metadata": {},
   "source": [
    "**Q2. Write a python program to extract the URL of the video thumbnails of the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "84695edc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs of the video thumbnails of the first five videos have been saved in thumbnail_urls.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extract the URLs of the video thumbnails of the first five videos\n",
    "thumbnail_urls = []\n",
    "for thumbnail in soup.select(\".yt-img-shadow\"):\n",
    "    thumbnail_urls.append(thumbnail[\"src\"])\n",
    "\n",
    "# Prepare data for CSV\n",
    "data = [{\"Thumbnail URL\": thumbnail_url} for thumbnail_url in thumbnail_urls[:5]]\n",
    "\n",
    "# Save the data in a CSV file\n",
    "filename = \"thumbnail_urls.csv\"\n",
    "fieldnames = [\"Thumbnail URL\"]\n",
    "with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"URLs of the video thumbnails of the first five videos have been saved in\", filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531a895e",
   "metadata": {},
   "source": [
    "**Q3. Write a python program to extract the title of the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a41e98f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Titles of the first five videos have been saved in video_titles.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extract the titles of the first five videos\n",
    "titles = []\n",
    "for title in soup.select(\"#video-title\"):\n",
    "    titles.append(title.get_text().strip())\n",
    "\n",
    "# Prepare data for CSV\n",
    "data = [{\"Title\": video_title} for video_title in titles[:5]]\n",
    "\n",
    "# Save the data in a CSV file\n",
    "filename = \"video_titles.csv\"\n",
    "fieldnames = [\"Title\"]\n",
    "with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"Titles of the first five videos have been saved in\", filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dbdd82",
   "metadata": {},
   "source": [
    "**Q4. Write a python program to extract the number of views of the first five videos.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9f3ca2c3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of views of the first five videos have been saved in video_views.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extract the number of views of the first five videos\n",
    "views = []\n",
    "for view in soup.select(\".style-scope.ytd-grid-video-renderer .ytd-video-meta-block\"):\n",
    "    views.append(view.get_text().strip().split()[0])\n",
    "\n",
    "# Prepare data for CSV\n",
    "data = [{\"Views\": video_views} for video_views in views[:5]]\n",
    "\n",
    "# Save the data in a CSV file\n",
    "filename = \"video_views.csv\"\n",
    "fieldnames = [\"Views\"]\n",
    "with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"Number of views of the first five videos have been saved in\", filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fcf6806a",
   "metadata": {},
   "source": [
    "**Q5. Python program to extract the time of posting of the first five videos and save them in a CSV file:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "06c13aaa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time of posting of the first five videos have been saved in video_post_times.csv\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import csv\n",
    "\n",
    "url = \"https://www.youtube.com/@PW-Foundation/videos\"\n",
    "\n",
    "# Send a GET request to the URL\n",
    "response = requests.get(url)\n",
    "\n",
    "# Create a BeautifulSoup object to parse the HTML content\n",
    "soup = BeautifulSoup(response.content, \"html.parser\")\n",
    "\n",
    "# Extract the time of posting of the first five videos\n",
    "post_times = []\n",
    "for post_time in soup.select(\".style-scope.ytd-grid-video-renderer .ytd-video-meta-block\"):\n",
    "    post_times.append(post_time.contents[1].get_text().strip())\n",
    "\n",
    "# Prepare data for CSV\n",
    "data = [{\"Post Time\": video_post_time} for video_post_time in post_times[:5]]\n",
    "\n",
    "# Save the data in a CSV file\n",
    "filename = \"video_post_times.csv\"\n",
    "fieldnames = [\"Post Time\"]\n",
    "with open(filename, mode=\"w\", encoding=\"utf-8\", newline=\"\") as file:\n",
    "    writer = csv.DictWriter(file, fieldnames=fieldnames)\n",
    "    writer.writeheader()\n",
    "    writer.writerows(data)\n",
    "\n",
    "print(\"Time of posting of the first five videos have been saved in\", filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ff4b28ae",
   "metadata": {},
   "source": [
    "# ------------------------------------------------------END---------------------------------------------------"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
