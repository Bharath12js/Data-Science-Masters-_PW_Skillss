{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "589ad85b",
   "metadata": {},
   "source": [
    "# Anomaly detection Assignment - 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc5174d5",
   "metadata": {},
   "source": [
    "Q1. What is anomaly detection and what is its purpose?\n",
    "\n",
    "Q2. What are the key challenges in anomaly detection?\n",
    "\n",
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "\n",
    "Q4. What are the main categories of anomaly detection algorithms?\n",
    "\n",
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "\n",
    "Q6. How does the LOF algorithm compute anomaly scores?\n",
    "\n",
    "Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "\n",
    "Q8. If a data point has only 2 neighbours of the same class within a radius of 0.5, what is its anomaly score \n",
    "using KNN with K=10?\n",
    "\n",
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the \n",
    "anomaly score for a data point that has an average path length of 5.0 compared to the average path \n",
    "length of the trees?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c71d7a5d",
   "metadata": {},
   "source": [
    "Q1. What is anomaly detection and what is its purpose?\n",
    "   - Anomaly detection, also known as outlier detection, is a data analysis technique used to identify observations or data points that deviate significantly from the majority of the data. The purpose of anomaly detection is to find rare and unusual patterns or instances that do not conform to the expected behavior of the dataset. It is often used for identifying fraud, errors, defects, or unusual events in various domains, such as finance, cybersecurity, manufacturing, and healthcare.\n",
    "\n",
    "Q2. What are the key challenges in anomaly detection?\n",
    "   - Key challenges in anomaly detection include:\n",
    "     1. Lack of Labeled Data: Anomaly detection is often performed in unsupervised or semi-supervised settings, where labeled anomalies are scarce or unavailable.\n",
    "     2. Data Imbalance: Anomalies are typically rare compared to normal instances, leading to class imbalance issues.\n",
    "     3. Diverse Anomalies: Anomalies can take various forms and may not follow a specific pattern, making detection challenging.\n",
    "     4. Concept Drift: The nature of anomalies may change over time, requiring adaptive detection methods.\n",
    "     5. High-Dimensional Data: Anomaly detection becomes more challenging in high-dimensional feature spaces.\n",
    "     6. Scalability: Efficiently detecting anomalies in large datasets is a computational challenge.\n",
    "     \n",
    "Q3. How does unsupervised anomaly detection differ from supervised anomaly detection?\n",
    "   - Unsupervised Anomaly Detection:\n",
    "     - Doesn't rely on labeled data.\n",
    "     - Identifies anomalies based on deviations from the majority of data points.\n",
    "     - Useful when labeled anomalies are scarce or unavailable.\n",
    "   - Supervised Anomaly Detection:\n",
    "     - Requires labeled data with anomalies and normal instances.\n",
    "     - Learns a model to distinguish anomalies from normal instances based on the labeled data.\n",
    "     - Typically results in a classification model that can classify new data points as anomalies or normal.\n",
    "\n",
    "Q4. What are the main categories of anomaly detection algorithms?\n",
    "   - Anomaly detection algorithms can be categorized into the following main types:\n",
    "     1. Statistical Methods: Use statistical models to identify anomalies based on deviations from statistical norms.\n",
    "     2. Machine Learning-Based: Utilize machine learning algorithms to learn patterns and detect anomalies.\n",
    "     3. Distance-Based: Measure the distance or similarity between data points and identify outliers as anomalies.\n",
    "     4. Clustering-Based: Detect anomalies by considering data points that do not belong to any cluster as outliers.\n",
    "     5. Density-Based: Define anomalies as data points in low-density regions of the data distribution.\n",
    "     6. Replicator Neural Networks: Use autoencoders or other neural network architectures to reconstruct data and flag discrepancies as anomalies.\n",
    "     7. Domain-Specific: Tailored approaches designed for specific application domains, such as fraud detection, network intrusion detection, and image anomaly detection.\n",
    "\n",
    "Q5. What are the main assumptions made by distance-based anomaly detection methods?\n",
    "   - Distance-based anomaly detection methods typically assume that anomalies are distant from normal data points in feature space. The key assumptions include:\n",
    "     1. Normal data points are tightly clustered and have similar characteristics.\n",
    "     2. Anomalies are isolated and significantly different from normal data points.\n",
    "     3. A distance or similarity metric can effectively measure the dissimilarity between data points.\n",
    "   \n",
    "Q6. How does the LOF algorithm compute anomaly scores?\n",
    "   - The Local Outlier Factor (LOF) algorithm computes anomaly scores as follows:\n",
    "     - For each data point, it calculates its Local Reachability Density (LRD) by considering the average density of its k nearest neighbors.\n",
    "     - For each data point, it computes the LRD of its k nearest neighbors and divides it by its own LRD to obtain the LOF.\n",
    "     - The LOF reflects how isolated a data point is compared to its neighbors. High LOF values indicate outliers or anomalies.\n",
    "\n",
    "Q7. What are the key parameters of the Isolation Forest algorithm?\n",
    "   - The key parameters of the Isolation Forest algorithm include:\n",
    "     1. Number of Trees (n_estimators): The number of isolation trees to build.\n",
    "     2. Maximum Tree Depth (max_depth): The maximum depth of each individual isolation tree.\n",
    "     3. Subsample Size (max_samples): The size of the random subsample used to build each tree.\n",
    "     4. Contamination: The estimated proportion of anomalies in the dataset (used for scoring).\n",
    "\n",
    "Q8. If a data point has only 2 neighbors of the same class within a radius of 0.5, what is its anomaly score using KNN with K=10?\n",
    "   - The anomaly score for a data point using KNN with K=10 depends on the relative distance of the data point to its K-nearest neighbors. In this case, having only 2 neighbors of the same class within a radius of 0.5 suggests that the data point is not well-supported by its neighbors and may be an outlier. Therefore, its KNN-based anomaly score is likely to be relatively high.\n",
    "\n",
    "Q9. Using the Isolation Forest algorithm with 100 trees and a dataset of 3000 data points, what is the anomaly score for a data point that has an average path length of 5.0 compared to the average path length of the trees?\n",
    "   - The anomaly score in the Isolation Forest algorithm is inversely related to the average path length. Lower average path lengths indicate that a data point is easier to isolate and, therefore, more likely to be an anomaly. In this case, having an average path length of 5.0 compared to the average path length of the trees would suggest that the data point is less isolated and has a lower anomaly score. The exact numeric score would depend on the specific details of the dataset and the Isolation Forest implementation used."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0670f7f6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
