{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c14f9590",
   "metadata": {},
   "source": [
    "# Callback Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "400b7286",
   "metadata": {},
   "source": [
    "Q1. Install and load the latest versions of TensorFlow and Keras. Print their versions.\n",
    "\n",
    "Q2. Load the Wine Quality dataset and explore its dimensions.\n",
    "Dataset link:https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\n",
    "Q3. Check for null values, identify categorical variables, and encode them.\n",
    "\n",
    "Q4. Separate the features and target variables from the dataframe.\n",
    "\n",
    "Q5. Perform a train-test split and divide the data into training, validation, and test datasets.\n",
    "\n",
    "Q6. Perform scaling on the dataset.\n",
    "\n",
    "Q7. Create at least 2 hidden layers and an output layer for the binary categorical variables.\n",
    "\n",
    "Q8. Create a Sequential model and add all the layers to it.\n",
    "\n",
    "Q9. Implement a TensorBoard callback to visualize and monitor the model's training process.\n",
    "\n",
    "Q10. Use Early Stopping to prevent overfitting by monitoring a chosen metric and stopping the training if\n",
    "no improvement is observed.\n",
    "\n",
    "Q11. Implement a ModelCheckpoint callback to save the best model based on a chosen metric during\n",
    "training.\n",
    "\n",
    "Q12. Print the model summary.\n",
    "\n",
    "Q13. Use binary cross-entropy as the loss function, Adam optimizer, and include the metric ['accuracy'].\n",
    "\n",
    "Q14. Compile the model with the specified loss function, optimizer, and metrics.\n",
    "\n",
    "Q15. Fit the model to the data, incorporating the TensorBoard, Early Stopping, and ModelCheckpoint\n",
    "callbacks.\n",
    "\n",
    "Q16. Get the model's parameters.\n",
    "\n",
    "Q17. Store the model's training history as a Pandas DataFrame\n",
    ".\n",
    "Q18. Plot the model's training history.\n",
    "\n",
    "Q19. Evaluate the model's performance using the test data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26d713d1",
   "metadata": {},
   "source": [
    " Make sure to install the necessary libraries using `pip install tensorflow keras pandas scikit-learn`.\n",
    "\n",
    "```python\n",
    "# Import necessary libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "import pandas as pd\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from tensorflow.keras.callbacks import TensorBoard, EarlyStopping, ModelCheckpoint\n",
    "import datetime\n",
    "\n",
    "# Q1: Install and load the latest versions of TensorFlow and Keras\n",
    "print(\"TensorFlow Version:\", tf.__version__)\n",
    "print(\"Keras Version:\", keras.__version__)\n",
    "\n",
    "# Q2: Load the Wine Quality dataset and explore its dimensions\n",
    "url = \"https://www.kaggle.com/datasets/nareshbhat/wine-quality-binary-classification\"\n",
    "# Assuming you've downloaded the dataset as \"winequality.csv\"\n",
    "wine_data = pd.read_csv(\"winequality.csv\")\n",
    "print(\"Dataset Dimensions:\", wine_data.shape)\n",
    "\n",
    "# Q3: Check for null values, identify categorical variables, and encode them\n",
    "print(\"Null Values:\\n\", wine_data.isnull().sum())\n",
    "categorical_vars = wine_data.select_dtypes(include=['object']).columns\n",
    "label_encoder = LabelEncoder()\n",
    "for var in categorical_vars:\n",
    "    wine_data[var] = label_encoder.fit_transform(wine_data[var])\n",
    "\n",
    "# Q4: Separate features and target variables\n",
    "X = wine_data.drop('target', axis=1)\n",
    "y = wine_data['target']\n",
    "\n",
    "# Q5: Train-test split\n",
    "X_train, X_temp, y_train, y_temp = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X_val, X_test, y_val, y_test = train_test_split(X_temp, y_temp, test_size=0.5, random_state=42)\n",
    "\n",
    "# Q6: Scaling\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_val_scaled = scaler.transform(X_val)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Q7 to Q11: Model creation with callbacks\n",
    "model = Sequential()\n",
    "model.add(Dense(64, activation='relu', input_dim=X_train.shape[1]))\n",
    "model.add(Dense(32, activation='relu'))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "# Q9: TensorBoard Callback\n",
    "log_dir = \"logs/fit/\" + datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\")\n",
    "tensorboard_callback = TensorBoard(log_dir=log_dir, histogram_freq=1)\n",
    "\n",
    "# Q10: Early Stopping Callback\n",
    "early_stopping_callback = EarlyStopping(monitor='val_loss', patience=3)\n",
    "\n",
    "# Q11: ModelCheckpoint Callback\n",
    "model_checkpoint_callback = ModelCheckpoint(\n",
    "    filepath=\"best_model.h5\",\n",
    "    save_best_only=True,\n",
    "    monitor='val_accuracy',\n",
    "    mode='max',\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "# Q8: Add layers to the model\n",
    "model = Sequential([Dense(64, activation='relu', input_dim=X_train.shape[1]),\n",
    "                    Dense(32, activation='relu'),\n",
    "                    Dense(1, activation='sigmoid')])\n",
    "\n",
    "# Q12: Print the model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Q13: Compile the model\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Q15: Fit the model with callbacks\n",
    "history = model.fit(X_train_scaled, y_train, epochs=20, validation_data=(X_val_scaled, y_val),\n",
    "                    callbacks=[tensorboard_callback, early_stopping_callback, model_checkpoint_callback])\n",
    "\n",
    "# Q16: Get the model parameters\n",
    "model.get_weights()\n",
    "\n",
    "# Q17: Store the model's training history as a Pandas DataFrame\n",
    "history_df = pd.DataFrame(history.history)\n",
    "\n",
    "# Q18: Plot the model's training history\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history_df['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history_df['val_accuracy'], label='Validation Accuracy')\n",
    "plt.xlabel('Epochs')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# Q19: Evaluate the model's performance using the test data\n",
    "test_loss, test_accuracy = model.evaluate(X_test_scaled, y_test)\n",
    "print(f'Test Loss: {test_loss}, Test Accuracy: {test_accuracy}')\n",
    "```\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37962931",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
