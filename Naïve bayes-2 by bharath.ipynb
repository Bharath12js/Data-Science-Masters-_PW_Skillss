{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ef6e2a08",
   "metadata": {},
   "source": [
    "# Na√Øve bayes-2 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8be19dce",
   "metadata": {},
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the\n",
    "company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the\n",
    "probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "\n",
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "\n",
    "Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "\n",
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "\n",
    "Q5. Assignment:\n",
    "Data preparation:\n",
    "Download the \"Spambase Data Set\" from the UCI Machine Learning Repository (https://archive.ics.uci.edu/ml/\n",
    "datasets/Spambase). This dataset contains email messages, where the goal is to predict whether a message\n",
    "is spam or not based on several input features.\n",
    "Implementation:\n",
    "Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using the\n",
    "scikit-learn library in Python. Use 10-fold cross-validation to evaluate the performance of each classifier on the\n",
    "dataset. You should use the default hyperparameters for each classifier.\n",
    "Results:\n",
    "Report the following performance metrics for each classifier:\n",
    "Accuracy\n",
    "Precision\n",
    "Recall\n",
    "F1 score\n",
    "Discussion:\n",
    "Discuss the results you obtained. Which variant of Naive Bayes performed the best? Why do you think that is\n",
    "the case? Are there any limitations of Naive Bayes that you observed?\n",
    "Conclusion:\n",
    "Summarise your findings and provide some suggestions for future work.\n",
    "\n",
    "Note: Create your assignment in Jupyter notebook and upload it to GitHub & share that github repository\n",
    "link through your dashboard. Make sure the repository is public.\n",
    "Note: This dataset contains a binary classification problem with multiple features. The dataset is\n",
    "relatively small, but it can be used to demonstrate the performance of the different variants of Naive\n",
    "Bayes on a real-world problem."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2552f745",
   "metadata": {},
   "source": [
    "Q1. A company conducted a survey of its employees and found that 70% of the employees use the company's health insurance plan, while 40% of the employees who use the plan are smokers. What is the probability that an employee is a smoker given that he/she uses the health insurance plan?\n",
    "\n",
    "To find the probability that an employee is a smoker given that he/she uses the health insurance plan, we can use conditional probability. We can use Bayes' theorem for this purpose. Let's denote the events as follows:\n",
    "\n",
    "- A: Employee uses the health insurance plan.\n",
    "- B: Employee is a smoker.\n",
    "\n",
    "We are given the following probabilities:\n",
    "- P(A) = 0.70 (probability that an employee uses the health insurance plan).\n",
    "- P(B|A) = 0.40 (probability that an employee is a smoker given that they use the plan).\n",
    "\n",
    "We want to find P(B|A), the probability that an employee is a smoker given that they use the plan.\n",
    "\n",
    "Using Bayes' theorem:\n",
    "\\[ P(B|A) = \\frac{P(A|B) \\cdot P(B)}{P(A)} \\]\n",
    "\n",
    "Here, P(A|B) is the probability that an employee uses the health insurance plan given that they are a smoker. We don't have this information, so we assume it's the same as P(A) since the survey didn't provide that conditional probability.\n",
    "\n",
    "So, we can calculate:\n",
    "\\[ P(B|A) = \\frac{P(A) \\cdot P(B)}{P(A)} = P(B) = 0.40 \\]\n",
    "\n",
    "Therefore, the probability that an employee is a smoker given that he/she uses the health insurance plan is 40%.\n",
    "\n",
    "Q2. What is the difference between Bernoulli Naive Bayes and Multinomial Naive Bayes?\n",
    "\n",
    "The key difference between Bernoulli Naive Bayes and Multinomial Naive Bayes lies in the types of data they are suitable for and the underlying assumptions:\n",
    "\n",
    "1. **Bernoulli Naive Bayes:**\n",
    "   - Suitable for binary data (where features are either present or absent).\n",
    "   - Assumes that features are binary (0 or 1) and that their presence or absence is independent.\n",
    "   - Commonly used for text classification problems, where each feature represents the presence or absence of a word in a document.\n",
    "   - Example: Spam detection, sentiment analysis.\n",
    "\n",
    "2. **Multinomial Naive Bayes:**\n",
    "   - Suitable for discrete data, typically count-based (e.g., word counts or term frequencies).\n",
    "   - Assumes that features follow a multinomial distribution (counts of occurrences).\n",
    "   - Often used for text classification when features represent word counts or frequencies in documents.\n",
    "   - Works well with integer-valued features that represent the number of occurrences.\n",
    "   - Example: Document classification based on word counts.\n",
    "\n",
    "In summary, Bernoulli Naive Bayes is designed for binary data with a focus on presence or absence, while Multinomial Naive Bayes is suitable for count-based discrete data, such as word counts or frequencies.\n",
    "\n",
    "Q3. How does Bernoulli Naive Bayes handle missing values?\n",
    "\n",
    "Bernoulli Naive Bayes, like other Naive Bayes variants, assumes that features are independent and that their presence or absence is represented by binary values (0 or 1). When dealing with missing values in Bernoulli Naive Bayes, you typically have a few options:\n",
    "\n",
    "1. **Impute Missing Values:** You can impute missing values by assigning them a specific value, such as 0 or 1, based on some criterion. For example, you might impute missing values with 0 to indicate the absence of a feature or with 1 to indicate the presence. The choice of imputation method should align with the specific problem and domain knowledge.\n",
    "\n",
    "2. **Treat Missing Values as a Separate Category:** Instead of imputing missing values, you can treat them as a separate category or feature level. This approach allows the model to learn from the absence of information explicitly.\n",
    "\n",
    "3. **Ignore Rows with Missing Values:** If missing values are relatively rare and don't significantly impact the dataset's size, you can choose to remove rows with missing values.\n",
    "\n",
    "The approach you choose depends on the nature of your data, the impact of missing values on your model's performance, and your domain-specific knowledge.\n",
    "\n",
    "Q4. Can Gaussian Naive Bayes be used for multi-class classification?\n",
    "\n",
    "Yes, Gaussian Naive Bayes can be used for multi-class classification tasks. Gaussian Naive Bayes is a variant of Naive Bayes that is suitable for continuous or real-valued features. It assumes that the features follow a Gaussian (normal) distribution within each class.\n",
    "\n",
    "In the context of multi-class classification, Gaussian Naive Bayes can be extended to handle multiple classes by applying the Naive Bayes principle independently for each class. When using Gaussian Naive Bayes for multi-class classification, the model calculates the likelihood of each class given the observed feature values, and the class with\n",
    "\n",
    " the highest likelihood is predicted.\n",
    "\n",
    "Here are the steps for using Gaussian Naive Bayes for multi-class classification:\n",
    "\n",
    "1. Calculate the class priors (prior probabilities) for each class based on the training data.\n",
    "\n",
    "2. Estimate the mean and variance of the feature values for each class.\n",
    "\n",
    "3. Given a new data point with feature values, calculate the likelihood of each class based on the Gaussian distribution parameters (mean and variance) for that class.\n",
    "\n",
    "4. Multiply the likelihood by the class prior for each class to obtain the unnormalized posterior probabilities.\n",
    "\n",
    "5. Normalize the posterior probabilities to ensure that they sum to 1.\n",
    "\n",
    "6. Predict the class with the highest posterior probability as the final prediction.\n",
    "\n",
    "Gaussian Naive Bayes is commonly used for multi-class classification when dealing with continuous data or data that can be approximated as continuous, such as sensor readings, measurements, or other real-valued features.\n",
    "\n",
    "Q5. Assignment: Implementing Naive Bayes Classifiers\n",
    "\n",
    "To complete the assignment of implementing Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers on the \"Spambase Data Set\" and evaluating their performance, you can follow these steps in a Jupyter notebook:\n",
    "\n",
    "1. Download the \"Spambase Data Set\" from the provided UCI Machine Learning Repository link.\n",
    "\n",
    "2. Load the dataset into your Python environment using a library like pandas.\n",
    "\n",
    "3. Preprocess the data by:\n",
    "   - Handling any missing values (if present).\n",
    "   - Splitting the data into features (input) and the target variable (output).\n",
    "   - Encoding the target variable (e.g., 0 for non-spam and 1 for spam).\n",
    "\n",
    "4. Implement Bernoulli Naive Bayes, Multinomial Naive Bayes, and Gaussian Naive Bayes classifiers using scikit-learn.\n",
    "\n",
    "5. Use 10-fold cross-validation to evaluate the performance of each classifier. You can use scikit-learn's `cross_val_score` or manually perform cross-validation.\n",
    "\n",
    "6. For each classifier, calculate the following performance metrics:\n",
    "   - Accuracy\n",
    "   - Precision\n",
    "   - Recall\n",
    "   - F1 score\n",
    "\n",
    "7. Discuss the results and compare the performance of the three Naive Bayes variants. Analyze which one performed the best and why. Mention any limitations or observations you made during the evaluation.\n",
    "\n",
    "8. Summarize your findings and provide suggestions for future work or improvements.\n",
    "\n",
    "Make sure to organize your Jupyter notebook with clear sections, explanations, and code comments to document each step. Once you've completed the assignment, upload your Jupyter notebook to a public GitHub repository and share the repository link through your dashboard for review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3620a9dd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bernoulli Naive Bayes Classifier:\n",
      "Accuracy: 0.8839\n",
      "Precision: 0.8870\n",
      "Recall: 0.8152\n",
      "F1 Score: 0.8481\n",
      "\n",
      "Multinomial Naive Bayes Classifier:\n",
      "Accuracy: 0.7863\n",
      "Precision: 0.7393\n",
      "Recall: 0.7215\n",
      "F1 Score: 0.7283\n",
      "\n",
      "Gaussian Naive Bayes Classifier:\n",
      "Accuracy: 0.8218\n",
      "Precision: 0.7104\n",
      "Recall: 0.9570\n",
      "F1 Score: 0.8131\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.naive_bayes import BernoulliNB, MultinomialNB, GaussianNB\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\n",
    "\n",
    "# Load the Spambase dataset\n",
    "url = \"https://archive.ics.uci.edu/ml/machine-learning-databases/spambase/spambase.data\"\n",
    "column_names = [f\"feature_{i}\" for i in range(57)] + [\"is_spam\"]\n",
    "data = pd.read_csv(url, header=None, names=column_names)\n",
    "\n",
    "# Split the data into features and target\n",
    "X = data.drop(\"is_spam\", axis=1)\n",
    "y = data[\"is_spam\"]\n",
    "\n",
    "# Encode the target variable (0 for non-spam, 1 for spam)\n",
    "label_encoder = LabelEncoder()\n",
    "y = label_encoder.fit_transform(y)\n",
    "\n",
    "# Initialize classifiers\n",
    "bernoulli_nb = BernoulliNB()\n",
    "multinomial_nb = MultinomialNB()\n",
    "gaussian_nb = GaussianNB()\n",
    "\n",
    "# Perform 10-fold cross-validation and evaluate each classifier\n",
    "def evaluate_classifier(classifier, name):\n",
    "    accuracy_scores = cross_val_score(classifier, X, y, cv=10, scoring=\"accuracy\")\n",
    "    precision_scores = cross_val_score(classifier, X, y, cv=10, scoring=\"precision\")\n",
    "    recall_scores = cross_val_score(classifier, X, y, cv=10, scoring=\"recall\")\n",
    "    f1_scores = cross_val_score(classifier, X, y, cv=10, scoring=\"f1\")\n",
    "    \n",
    "    print(f\"{name} Naive Bayes Classifier:\")\n",
    "    print(f\"Accuracy: {accuracy_scores.mean():.4f}\")\n",
    "    print(f\"Precision: {precision_scores.mean():.4f}\")\n",
    "    print(f\"Recall: {recall_scores.mean():.4f}\")\n",
    "    print(f\"F1 Score: {f1_scores.mean():.4f}\")\n",
    "    print()\n",
    "\n",
    "# Evaluate Bernoulli Naive Bayes\n",
    "evaluate_classifier(bernoulli_nb, \"Bernoulli\")\n",
    "\n",
    "# Evaluate Multinomial Naive Bayes\n",
    "evaluate_classifier(multinomial_nb, \"Multinomial\")\n",
    "\n",
    "# Evaluate Gaussian Naive Bayes\n",
    "evaluate_classifier(gaussian_nb, \"Gaussian\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3049a663",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
